# ğŸ“˜ README â€“ Etapa 3: Analiza È™i PregÄƒtirea Setului de Date pentru ReÈ›ele Neuronale

**Disciplina:** ReÈ›ele Neuronale  
**InstituÈ›ie:** POLITEHNICA BucureÈ™ti â€“ FIIR  
**Student:** Mocanu Vlad-Cristian 
**Data:** 20/11/2025  

---

## Introducere

Acest document descrie activitÄƒÈ›ile realizate Ã®n **Etapa 3**, Ã®n care se analizeazÄƒ È™i se preproceseazÄƒ setul de date necesar proiectului â€ReÈ›ele Neuronale". Scopul etapei este pregÄƒtirea corectÄƒ a datelor pentru instruirea modelului RN, respectÃ¢nd bunele practici privind calitatea, consistenÈ›a È™i reproductibilitatea datelor.

---

##  1. Structura Repository-ului Github (versiunea Etapei 3)

```
project-name/
â”œâ”€â”€ README.md
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ datasets/          # descriere seturi de date, surse, diagrame
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # date brute
â”‚   â”œâ”€â”€ processed/         # date curÄƒÈ›ate È™i transformate
â”‚   â”œâ”€â”€ train/             # set de instruire
â”‚   â”œâ”€â”€ validation/        # set de validare
â”‚   â””â”€â”€ test/              # set de testare
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/     # funcÈ›ii pentru preprocesare
â”‚   â”œâ”€â”€ data_acquisition/  # generare / achiziÈ›ie date (dacÄƒ existÄƒ)
â”‚   â””â”€â”€ neural_network/    # implementarea RN (Ã®n etapa urmÄƒtoare)
â”œâ”€â”€ config/                # fiÈ™iere de configurare
â””â”€â”€ requirements.txt       # dependenÈ›e Python (dacÄƒ aplicabil)
```

---

##  2. Descrierea Setului de Date

### 2.1 Sursa datelor

* **Origine:** Senzori Robot,simulare
* **Modul de achiziÈ›ie:** â˜ Senzori reali / âœ” Simulare / â˜ FiÈ™ier extern / â˜ Generare programaticÄƒ
* **Perioada / condiÈ›iile colectÄƒrii:** Noiembrie 2025-Ianuarie 2026

### 2.2 Caracteristicile dataset-ului

* **NumÄƒr total de observaÈ›ii:6000
* **NumÄƒr de caracteristici (features):** 3
* **Tipuri de date:** âœ” Numerice / â˜ Categoriale / â˜ Temporale / â˜ Imagini
* **Format fiÈ™iere:** â˜ CSV / âœ” TXT / â˜ JSON / â˜ PNG / â˜ Altele: [...]

### 2.3 Descrierea fiecÄƒrei caracteristici

| **CaracteristicÄƒ** | **Tip** | **Unitate** | **Descriere** | **Domeniu valori** |
|-------------------|---------|-------------|---------------|--------------------|
| acceleratie | numeric | mm/s^2 | Acceleratie robotului | 0â€“150 |
| pozitie | numeric | mm | Pozitia robotului | {x,y} |
| viteza | numeric | mm/s | Viteza robotului | 0-150 |


**FiÈ™ier recomandat:**  `data/README.md`

---

##  3. Analiza Exploratorie a Datelor (EDA) â€“ Sintetic

### 3.1 Statistici descriptive aplicate

* **Medie, medianÄƒ, deviaÈ›ie standard** : Deoarece datele sunt generate uniform pentru traiectoria idealÄƒ, media poziÈ›iilor este centratÄƒ Ã®n jurul valorii de 500 mm. DeviaÈ›ia standard a erorii variazÄƒ Ã®n funcÈ›ie de clasÄƒ: micÄƒ pentru 'Precizie Mare' È™i ridicatÄƒ pentru 'Precizie MicÄƒ'
  
* **Minâ€“max È™i quartile** : Domeniul valorilor de intrare este fixat prin parametrii de simulare: PoziÈ›ie [0 - 1000] mm, VitezÄƒ [0 - 100] mm/s, AcceleraÈ›ie [0 - 50] mm/sÂ². Nu existÄƒ valori care sÄƒ depÄƒÈ™eascÄƒ aceste limite fizice impuse.
  
* **DistribuÈ›ii pe caracteristici** (histograme) : Caracteristicile 'Ideale' urmeazÄƒ o distribuÈ›ie uniformÄƒ (acoperÄƒ tot spaÈ›iul de lucru). Caracteristicile 'Reale' urmeazÄƒ o distribuÈ›ie uniformÄƒ suprapusÄƒ cu un zgomot Gaussian (distribuÈ›ie normalÄƒ), specific fiecÄƒrei clase de eroare.
  
* **Identificarea outlierilor** (IQR / percentile) : Ãn acest set de date, 'outlierii' (valorile cu abateri mari) nu sunt erori de date, ci reprezintÄƒ instanÈ›ele clasei 'Precizie MicÄƒ'. Acestea sunt esenÈ›iale pentru ca modelul sÄƒ Ã®nveÈ›e sÄƒ detecteze defectele.

### 3.2 Analiza calitÄƒÈ›ii datelor

* **Detectarea valorilor lipsÄƒ** (% pe coloanÄƒ) : 0% valori lipsÄƒ. Fiind un set de date sintetic generat algoritmic, toate cÃ¢mpurile sunt completate automat la generare. Nu necesitÄƒ imputare.
  
* **Detectarea valorilor inconsistente sau eronate** : Nu existÄƒ valori inconsistente (ex: vitezÄƒ negativÄƒ sau acceleraÈ›ie infinitÄƒ) deoarece funcÈ›iile de generare folosesc np.abs() È™i limite fizice hard-codate. Datele respectÄƒ legile cinematice de bazÄƒ.
  
* **Identificarea caracteristicilor redundante sau puternic corelate** : ExistÄƒ o corelaÈ›ie puternicÄƒ (>0.9) Ã®ntre coloanele 'Ideal' È™i 'Real' corespunzÄƒtoare (ex: P_IX vs P_RX). AceastÄƒ redundanÈ›Äƒ este intenÈ›ionatÄƒ È™i necesarÄƒ, deoarece diferenÈ›a subtilÄƒ dintre ele (reziduul) este exact informaÈ›ia pe care ReÈ›eaua NeuronalÄƒ trebuie sÄƒ o Ã®nveÈ›e.

### 3.3 Probleme identificate

[exemplu] Feature X are 8% valori lipsÄƒ:

ÃnlocuieÈ™te cu: "DiferenÈ›e majore de scarÄƒ Ã®ntre caracteristici: PoziÈ›ia are valori pÃ¢nÄƒ la 1000, Ã®n timp ce AcceleraÈ›ia doar pÃ¢nÄƒ la 50. Acest lucru impune obligatoriu Normalizarea (MinMax Scaling) Ã®nainte de antrenare."

[exemplu] DistribuÈ›ia feature Y este puternic neuniformÄƒ:

ÃnlocuieÈ™te cu: "DistribuÈ›ie perfect echilibratÄƒ a claselor: Nu existÄƒ 'Class Imbalance'. Setul a fost generat forÈ›at cu 33% eÈ™antioane pentru fiecare dintre cele 3 clase (Mare, Medie, MicÄƒ), eliminÃ¢nd riscul de biasare a modelului."

[exemplu] Variabilitate ridicatÄƒ Ã®n clase:

ÃnlocuieÈ™te cu: "Suprapunere marginalÄƒ la graniÈ›a claselor: ExistÄƒ o uÈ™oarÄƒ zonÄƒ de suprapunere probabilisticÄƒ Ã®ntre erorile clasei 'Medie' È™i 'MicÄƒ', simulÃ¢nd incertitudinea realÄƒ a senzorilor, ceea ce poate duce la o eroare micÄƒ de clasificare la testare."

---

##  4. Preprocesarea Datelor

### 4.1 CurÄƒÈ›area datelor

  4.1 CurÄƒÈ›area datelor
Eliminare duplicatelor:

Nu a fost necesarÄƒ o etapÄƒ explicitÄƒ, deoarece datele sunt generate algoritmic cu o componentÄƒ de zgomot aleatoriu (Gaussian), ceea ce asigurÄƒ unicitatea fiecÄƒrui vector de intrare.

Tratarea valorilor lipsÄƒ:

Procent valori lipsÄƒ: 0%.

MetodÄƒ: Nu se aplicÄƒ (datele sunt complete prin construcÈ›ie).

Tratarea outlierilor:

Nu s-a aplicat eliminarea outlierilor (ex: IQR), deoarece valorile extreme (erori mari de poziÈ›ie) reprezintÄƒ tocmai clasa de interes "Precizie MicÄƒ". Eliminarea lor ar fi redus capacitatea modelului de a detecta defectele grave.

### 4.2 Transformarea caracteristicilor

   Normalizare:

MetodÄƒ: Min-Max Scaling (scalare Ã®n intervalul [0, 1]).

Motiv: DiferenÈ›ele mari de scarÄƒ Ã®ntre PoziÈ›ie (0-1000 mm) È™i AcceleraÈ›ie (0-50 mm/sÂ²) ar fi destabilizat antrenarea reÈ›elei neuronale.

Implementare: S-a utilizat clasa MinMaxScaler din biblioteca Scikit-Learn.

Encoding pentru variabile categoriale:

MetodÄƒ: One-Hot Encoding.

Aplicare: Variabila È›intÄƒ (eticheta clasei: 0, 1, 2) a fost transformatÄƒ Ã®n vectori binari (ex: Clasa 0 -> [1, 0, 0]) folosind funcÈ›ia to_categorical din Keras.

Ajustarea dezechilibrului de clasÄƒ:

Nu a fost necesarÄƒ (not applicable). Setul de date a fost generat echilibrat din start (33% pentru fiecare clasÄƒ).

### 4.3 Structurarea seturilor de date

   ÃmpÄƒrÈ›ire utilizatÄƒ:

80% â€“ Set de Antrenare (Training)

20% â€“ Set de Testare (Testing)

(Validarea s-a fÄƒcut implicit pe setul de test Ã®n timpul antrenÄƒrii prin parametrul validation_data).

Principii respectate:

Stratificare: ÃmpÄƒrÈ›irea a fost aleatorie, dar avÃ¢nd un set mare È™i echilibrat, distribuÈ›ia claselor s-a pÄƒstrat uniformÄƒ Ã®n ambele seturi.

Data Leakage (Scurgere de informaÈ›ie): S-a evitat prin calcularea parametrilor de scalare (fit) DOAR pe setul de antrenare, iar apoi s-a aplicat transformarea (transform) pe setul de test.

### 4.4 Salvarea rezultatelor preprocesÄƒrii

   Date preprocesate:

Datele brute au fost salvate Ã®n fiÈ™ierul dataset_final.csv pentru documentare.

Obiecte de preprocesare:

Obiectul scaler (MinMaxScaler) nu a fost salvat fizic Ã®n acest prototip, fiind re-iniÈ›ializat la fiecare rulare, dar Ã®ntr-un mediu de producÈ›ie ar fi salvat folosind biblioteca joblib.

---

##  5. FiÈ™iere Generate Ã®n AceastÄƒ EtapÄƒ

* `data/raw/` â€“ date brute
* `data/processed/` â€“ date curÄƒÈ›ate & transformate
* `data/train/`, `data/validation/`, `data/test/` â€“ seturi finale
* `src/preprocessing/` â€“ codul de preprocesare
* `data/README.md` â€“ descrierea dataset-ului

---

##  6. Stare EtapÄƒ (de completat de student)

- [x ] StructurÄƒ repository configuratÄƒ
- [x ] Dataset analizat (EDA realizatÄƒ)
- [ x] Date preprocesate
- [ x] Seturi train/val/test generate
- [x ] DocumentaÈ›ie actualizatÄƒ Ã®n README + `data/README.md`

---
