# ğŸ“˜ README â€“ Etapa 5: Configurarea È™i Antrenarea Modelului RN

**Disciplina:** ReÈ›ele Neuronale  
**InstituÈ›ie:** POLITEHNICA BucureÈ™ti â€“ FIIR  
**Student:** Mocanu Vlad-Cristian  
**Link Repository GitHub:** https://github.com/MocanuVlad9528532/Proiect-RN.git 
**Data predÄƒrii:** 12/11/2025

---

## Scopul Etapei 5

AceastÄƒ etapÄƒ corespunde punctului **6. Configurarea È™i antrenarea modelului RN** din lista de 9 etape - slide 2 **RN Specificatii proiect.pdf**.

**Obiectiv principal:** Antrenarea efectivÄƒ a modelului RN definit Ã®n Etapa 4, evaluarea performanÈ›ei È™i integrarea Ã®n aplicaÈ›ia completÄƒ.

**Pornire obligatorie:** Arhitectura completÄƒ È™i funcÈ›ionalÄƒ din Etapa 4:
- State Machine definit È™i justificat
- Cele 3 module funcÈ›ionale (Data Logging, RN, UI)
- Minimum 40% date originale Ã®n dataset

---

## PREREQUISITE â€“ Verificare Etapa 4 (OBLIGATORIU)

## PREREQUISITE â€“ Verificare Etapa 4 (OBLIGATORIU)

**Ãnainte de a Ã®ncepe Etapa 5, verificaÈ›i cÄƒ aveÈ›i din Etapa 4:**

- [x] **State Machine** definit È™i documentat Ã®n `docs/state_machine.png` (Diagrama de flux realizatÄƒ cu Mermaid/PNG)
- [x] **ContribuÈ›ie â‰¥40% date originale** Ã®n `baza_de_date_robot.csv` (100% date generate prin simulare cinematicÄƒ Python)
- [x] **Modul 1 (Data Logging)** funcÈ›ional - produce CSV-uri (FuncÈ›ia `genereaza_set_date` din `antrenare.py`)
- [x] **Modul 2 (RN)** cu arhitecturÄƒ definitÄƒ (Modelul MLP este definit Ã®n `antrenare.py` È™i salvat ca `model_spdt.h5`)
- [x] **Modul 3 (UI/Web Service)** funcÈ›ional cu model dummy/antrenat (Scriptul `testare.py` realizeazÄƒ vizualizarea graficÄƒ)
- [x] **Tabelul "Nevoie â†’ SoluÈ›ie â†’ Modul"** complet Ã®n README Etapa 4

**DacÄƒ oricare din punctele de mai sus lipseÈ™te â†’ reveniÈ›i la Etapa 4 Ã®nainte de a continua.**

---

## PregÄƒtire Date pentru Antrenare 

### DacÄƒ aÈ›i adÄƒugat date noi Ã®n Etapa 4 (contribuÈ›ia de 40%):

**TREBUIE sÄƒ refaceÈ›i preprocesarea pe dataset-ul COMBINAT:**

Exemplu:
```bash
# 1. Combinare date vechi (Etapa 3) + noi (Etapa 4)
python src/preprocessing/combine_datasets.py

# 2. Refacere preprocesare COMPLETÄ‚
python src/preprocessing/data_cleaner.py
python src/preprocessing/feature_engineering.py
python src/preprocessing/data_splitter.py --stratify --random_state 42

# Verificare finalÄƒ:
# data/train/ â†’ trebuie sÄƒ conÈ›inÄƒ date vechi + noi
# data/validation/ â†’ trebuie sÄƒ conÈ›inÄƒ date vechi + noi
# data/test/ â†’ trebuie sÄƒ conÈ›inÄƒ date vechi + noi
```

** ATENÈšIE - FolosiÈ›i ACEIAÈ˜I parametri de preprocesare:**
- AcelaÈ™i `scaler` salvat Ã®n `config/preprocessing_params.pkl`
- AceiaÈ™i proporÈ›ii split: 70% train / 15% validation / 15% test
- AcelaÈ™i `random_state=42` pentru reproducibilitate

**Verificare rapidÄƒ:**
```python
import pandas as pd
train = pd.read_csv('data/train/X_train.csv')
print(f"Train samples: {len(train)}")  # Trebuie sÄƒ includÄƒ date noi
```

---

##  CerinÈ›e Structurate pe 3 Niveluri

### Nivel 1 â€“ Obligatoriu pentru ToÈ›i (70% din punctaj)

CompletaÈ›i **TOATE** punctele urmÄƒtoare:

1. **Antrenare model** definit Ã®n Etapa 4 pe setul final de date (â‰¥40% originale)
2. **Minimum 10 epoci**, batch size 8â€“32
3. **ÃmpÄƒrÈ›ire stratificatÄƒ** train/validation/test: 70% / 15% / 15%
4. **Tabel justificare hiperparametri** (vezi secÈ›iunea de mai jos - OBLIGATORIU)
5. **Metrici calculate pe test set:**
   - **AcurateÈ›e â‰¥ 65%**
   - **F1-score (macro) â‰¥ 0.60**
6. **Salvare model antrenat** Ã®n `models/trained_model.h5` (Keras/TensorFlow) sau `.pt` (PyTorch) sau `.lvmodel` (LabVIEW)
7. **Integrare Ã®n UI din Etapa 4:**
   - UI trebuie sÄƒ Ã®ncarce modelul ANTRENAT (nu dummy)
   - InferenÈ›Äƒ REALÄ‚ demonstratÄƒ
   - Screenshot Ã®n `docs/screenshots/inference_real.png`

#### Tabel Hiperparametri È™i JustificÄƒri (OBLIGATORIU - Nivel 1)

CompletaÈ›i tabelul cu hiperparametrii folosiÈ›i È™i **justificaÈ›i fiecare alegere**:

| **Hiperparametru** | **Valoare AleasÄƒ** | **Justificare** |
|--------------------|-------------------|-----------------|
| Learning rate | 0.001 (Default) | Valoare standard pentru optimizatorul Adam; a asigurat o convergenÈ›Äƒ rapidÄƒ È™i stabilÄƒ a funcÈ›iei de cost (Loss) fÄƒrÄƒ oscilaÈ›ii. |
| Batch size | 32 | Compromis optim Ã®ntre viteza de actualizare a greutÄƒÈ›ilor È™i stabilitatea gradientului pentru setul de antrenare de 4.200 eÈ™antioane. |
| Number of epochs | 20 | Analiza curbei de Ã®nvÄƒÈ›are a arÄƒtat atingerea platoului (convergenÈ›Äƒ) Ã®n jurul epocii 12. S-au ales 20 pentru siguranÈ›Äƒ, fÄƒrÄƒ overfitting. |
| Optimizer | Adam | Algoritm adaptiv eficient pentru date cu zgomot (Gaussian noise), care nu necesitÄƒ ajustarea manualÄƒ a ratei de Ã®nvÄƒÈ›are. |
| Loss function | Categorical Crossentropy | FuncÈ›ia matematicÄƒ obligatorie pentru probleme de clasificare Multi-Class (3 clase) cu etichete One-Hot Encoded. |
| Activation functions | ReLU (hidden), Softmax (output) | **ReLU** Ã®n straturile ascunse (16/12 neuroni) pentru a preveni dispariÈ›ia gradientului. **Softmax** la ieÈ™ire pentru a obÈ›ine o distribuÈ›ie de probabilitate (suma=1). |

**Justificare detaliatÄƒ batch size:**
```text
Am ales batch_size=32 pentru setul nostru de date.
Calcul concret: Avem 4.200 samples de antrenare (70% din 6.000) â†’ 4.200 / 32 â‰ˆ 132 paÈ™i (iteraÈ›ii) per epocÄƒ.

AceastÄƒ valoare oferÄƒ un echilibru ideal pentru proiectul SPDT:
1. Stabilitate: Gradientul este calculat pe baza mediei a 32 de exemple, reducÃ¢nd zgomotul specific datelor generate sintetic.
2. VitezÄƒ: ReÈ›eaua Ã®È™i actualizeazÄƒ greutÄƒÈ›ile de 132 de ori pe epocÄƒ, permiÈ›Ã¢nd o Ã®nvÄƒÈ›are rapidÄƒ (convergenÈ›Äƒ Ã®n sub 15 epoci).
3. Generalizare: Batch-ul nu este nici prea mare (care ar duce la o estimare prea "netedÄƒ" È™i blocare Ã®n minime locale), nici prea mic (care ar face antrenarea instabilÄƒ).

**Resurse Ã®nvÄƒÈ›are rapidÄƒ:**
- ÃmpÄƒrÈ›ire date: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html (video 3 min: https://youtu.be/1NjLMWSGosI?si=KL8Qv2SJ1d_mFZfr)  
- Antrenare simplÄƒ Keras: https://keras.io/examples/vision/mnist_convnet/ (secÈ›iunea â€Trainingâ€)  
- Antrenare simplÄƒ PyTorch: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-an-image-classifier (video 2 min: https://youtu.be/ORMx45xqWkA?si=FXyQEhh0DU8VnuVJ)  
- F1-score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html (video 4 min: https://youtu.be/ZQlEcyNV6wc?si=VMCl8aGfhCfp5Egi)
```

---

### Nivel 2 â€“ Recomandat (85-90% din punctaj)

IncludeÈ›i **TOATE** cerinÈ›ele Nivel 1 + urmÄƒtoarele:

1. **Early Stopping** - oprirea antrenÄƒrii dacÄƒ `val_loss` nu scade Ã®n 5 epoci consecutive
2. **Learning Rate Scheduler** - `ReduceLROnPlateau` sau `StepLR`
3. **AugmentÄƒri relevante domeniu:**
   - VibraÈ›ii motor: zgomot gaussian calibrat, jitter temporal
   - Imagini industriale: slight perspective, lighting variation (nu rotaÈ›ii simple!)
   - Serii temporale: time warping, magnitude warping
4. **Grafic loss È™i val_loss** Ã®n funcÈ›ie de epoci salvat Ã®n `docs/loss_curve.png`
5. **AnalizÄƒ erori context industrial** (vezi secÈ›iunea dedicatÄƒ mai jos - OBLIGATORIU Nivel 2)

**Indicatori È›intÄƒ Nivel 2:**
- **AcurateÈ›e â‰¥ 75%**
- **F1-score (macro) â‰¥ 0.70**

**Resurse Ã®nvÄƒÈ›are (aplicaÈ›ii industriale):**
- Albumentations: https://albumentations.ai/docs/examples/   
- Early Stopping + ReduceLROnPlateau Ã®n Keras: https://keras.io/api/callbacks/   
- Scheduler Ã®n PyTorch: https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate 

---

### Nivel 3 â€“ Bonus (pÃ¢nÄƒ la 100%)

**Punctaj bonus per activitate:**
### Nivel 3 (Bonus): Comparare Arhitecturi È™i AnalizÄƒ Erori

Pentru a valida alegerea reÈ›elei neuronale (MLP), am comparat performanÈ›a acesteia cu un algoritm clasic robust, **Random Forest**.

| ArhitecturÄƒ | AcurateÈ›e (Test) | LatenÈ›Äƒ (ms/sample) | Avantaje | Dezavantaje |
| :--- | :--- | :--- | :--- | :--- |
| **MLP (Propus)** | **99.25%** | 0.103 ms | AcurateÈ›e net superioarÄƒ (+7% faÈ›Äƒ de RF), capabil sÄƒ Ã®nveÈ›e relaÈ›ii complexe neliniare. | NecesitÄƒ normalizarea datelor (MinMaxScaling). |
| Random Forest | 92.67% | **0.006 ms** | Extrem de rapid la inferenÈ›Äƒ, nu necesitÄƒ scalare. | AcurateÈ›e mai micÄƒ, rateazÄƒ cazurile fine de la graniÈ›a dintre clase. |

**Justificare Alegere FinalÄƒ:**
Am ales **MLP (ReÈ›ea NeuronalÄƒ)** deoarece diferenÈ›a de acurateÈ›e este semnificativÄƒ (+6.58%). DeÈ™i Random Forest este mai rapid, latenÈ›a MLP-ului de **0.1 ms** este deja de 500 de ori mai rapidÄƒ decÃ¢t cerinÈ›a de timp real (50ms), deci viteza nu este o problemÄƒ, iar calitatea predicÈ›iei primeazÄƒ.

### AnalizÄƒ Erori (Misclassification)

Modelul a comis doar **9 erori** din totalul setului de testare. AnalizÃ¢nd primele exemple, am identificat cauza:

* **Exemplu:** Real: `Medie` vs PredicÈ›ie: `Mare`
* **Valori:** Erorile de poziÈ›ie au fost Ã®ntre `13.09 mm` È™i `18.72 mm`.
* **CauzÄƒ (Feature Conflict):** Clasa "Medie" este centratÄƒ pe 12mm eroare. Aceste exemple s-au aflat la limita inferioarÄƒ a defectului. Probabil cÄƒ, deÈ™i poziÈ›ia era uÈ™or decalatÄƒ, profilul de **VitezÄƒ È™i AcceleraÈ›ie** a fost foarte stabil ("curat"), ceea ce a indus reÈ›eaua Ã®n eroare, clasificÃ¢nd miÈ™carea ca fiind "De precizie Mare".

**Resurse bonus:**
- Export ONNX din PyTorch: [PyTorch ONNX Tutorial](https://pytorch.org/tutorials/beginner/onnx/export_simple_model_to_onnx_tutorial.html)
- TensorFlow Lite converter: [TFLite Conversion Guide](https://www.tensorflow.org/lite/convert)
- Confusion Matrix analizÄƒ: [Scikit-learn Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)

---

## Verificare ConsistenÈ›Äƒ cu State Machine (Etapa 4 -> Etapa 5)

Implementarea din Etapa 5 respectÄƒ fidel stÄƒrile definite Ã®n diagrama State Machine, asigurÃ¢nd coerenÈ›a Ã®ntre faza de proiectare È™i cea de execuÈ›ie software.

**Tabel de corespondenÈ›Äƒ pentru Proiectul SPDT (Monitorizare CinematicÄƒ Robot):**

| **Stare din State Machine** | **Implementare concretÄƒ Ã®n Cod (Etapa 5)** | **FiÈ™ier sursÄƒ** |
|-----------------------------|--------------------------------------------|------------------|
| `DATA_GENERATION` | Generare scenariu random (PoziÈ›ie/VitezÄƒ) care simuleazÄƒ citirea instantanee a senzorilor. | `testare_etapa5.py` |
| `PREPROCESS` | ÃncÄƒrcarea scaler-ului salvat (`scaler_spdt.gz`) È™i normalizarea datelor brute la intervalul [0, 1]. | `testare_etapa5.py` |
| `RN_INFERENCE` | Executarea `model.predict()` folosind modelul antrenat È™i salvat (`trained_model.h5`). | `testare_etapa5.py` |
| `DECISION_LOGIC` | Aplicarea `np.argmax` pe vectorul de probabilitÄƒÈ›i pentru a stabili clasa finalÄƒ (Mare/Medie/MicÄƒ). | `testare_etapa5.py` |
| `HMI_VISUALIZATION` | Randarea graficÄƒ a "Digital Twin-ului" (Punct Ideal vs Real) È™i afiÈ™area textului de diagnozÄƒ. | `testare_etapa5.py` |

---

**Snippet din codul UI (`testare_etapa5.py`) care demonstreazÄƒ fluxul:**

```python
# 1. ACQUIRE (Simulare)
p_ix = np.random.uniform(200, 800) # ... generare date brute

# 2. PREPROCESS (Consistent cu antrenarea)
scaler = joblib.load('models/scaler_spdt.gz')
input_scaled = scaler.transform(input_raw)

# 3. INFERENCE (State-ul principal AI)
model = load_model('models/trained_model.h5')
pred_prob = model.predict(input_scaled)

# 4. DECISION & ALERT
clasa_idx = np.argmax(pred_prob)
if clasa_idx == 2: # Clasa Precizie MicÄƒ
    print(">>> ALERTA: DEFECT CRITIC DETECTAT!")
```

## AnalizÄƒ Erori Ã®n Context Industrial (OBLIGATORIU Nivel 2)

**Nu e suficient sÄƒ raportaÈ›i doar acurateÈ›ea globalÄƒ.** AnalizaÈ›i performanÈ›a Ã®n contextul aplicaÈ›iei voastre industriale:

### 5. AnalizÄƒ DetaliatÄƒ a Erorilor È™i Impact Industrial

#### 1. Pe ce clase greÈ™eÈ™te cel mai mult modelul?

**RÄƒspuns:**
Matricea de Confuzie È™i analiza erorilor individuale aratÄƒ cÄƒ modelul tinde sÄƒ confunde clasa **'Precizie Medie' (Real)** cu clasa **'Precizie Mare' (PredicÈ›ie)**.

Concret, Ã®n scenariile de test, majoritatea erorilor au apÄƒrut cÃ¢nd abaterea de poziÈ›ie a fost Ã®ntre **13mm È™i 18mm** (zona de graniÈ›Äƒ inferioarÄƒ a clasei Medii).
**CauzÄƒ posibilÄƒ:** DeÈ™i poziÈ›ia avea o abatere semnificativÄƒ pentru a fi catalogatÄƒ drept "Medie", profilurile de VitezÄƒ È™i AcceleraÈ›ie au rÄƒmas relativ "curate" (fÄƒrÄƒ zgomot mare/vibraÈ›ii), ceea ce a indus reÈ›eaua Ã®n eroare, clasificÃ¢nd comportamentul drept "Optim/Mare".

#### 2. Ce caracteristici ale datelor cauzeazÄƒ erori?

**RÄƒspuns:**
Modelul are performanÈ›Äƒ mai slabÄƒ Ã®n cazurile de **"Boundary Effect"** (GraniÈ›Äƒ Ã®ntre clase).
Caracteristicile care cauzeazÄƒ confuzia sunt suprapunerile distribuÈ›iilor Gaussiene. CÃ¢nd un senzor genereazÄƒ o valoare aflatÄƒ la "coada" distribuÈ›iei (ex: o eroare micÄƒ pentru clasa Medie care se suprapune matematic cu o eroare mare pentru clasa Mare), reÈ›eaua neuronalÄƒ are dificultÄƒÈ›i Ã®n a trasa o linie de demarcaÈ›ie perfectÄƒ, mai ales dacÄƒ zgomotul pe derivatele de ordin superior (vitezÄƒ/acceleraÈ›ie) este redus.

#### 3. Ce implicaÈ›ii are pentru aplicaÈ›ia industrialÄƒ?

**RÄƒspuns:**
Analiza impactului pentru Robotul Industrial SPDT:

* **FALSE NEGATIVES (Real: UzurÄƒ Medie/CriticÄƒ â†’ PredicÈ›ie: FuncÈ›ionare OptimÄƒ):**
    * **CRITIC:** Robotul continuÄƒ sÄƒ opereze cu eroare, ducÃ¢nd la rebutarea pieselor (ex: sudurÄƒ decalatÄƒ cu 1.5cm) sau chiar coliziuni uÈ™oare. Acesta este cel mai periculos scenariu.
* **FALSE POSITIVES (Real: Optim â†’ PredicÈ›ie: UzurÄƒ):**
    * **ACCEPTABIL:** Linia se opreÈ™te pentru o verificare de mentenanÈ›Äƒ inutilÄƒ. Se pierde timp È™i bani, dar se pÄƒstreazÄƒ siguranÈ›a echipamentului È™i calitatea produsului.

**Prioritate:** Minimizarea drasticÄƒ a *False Negatives* (nu vrem sÄƒ livrÄƒm piese defecte).
**SoluÈ›ie operaÈ›ionalÄƒ:** Ajustarea deciziei - dacÄƒ probabilitatea pentru clasa 'Medie' depÄƒÈ™eÈ™te 30% (chiar dacÄƒ 'Mare' are 60%), sistemul va ridica totuÈ™i un avertisment preventiv (Bias spre siguranÈ›Äƒ).

#### 4. Ce mÄƒsuri corective propuneÈ›i?

**RÄƒspuns:**
MÄƒsuri corective propuse pentru versiunea 2.0 a sistemului:

1.  **Antrenare cu "Cost-Sensitive Learning":** Penalizarea mai durÄƒ a erorilor de tip False Negative Ã®n funcÈ›ia de Loss (ex: greÈ™eala de a nu detecta un defect costÄƒ de 10 ori mai mult decÃ¢t o alarmÄƒ falsÄƒ).
2.  **Augmentare specificÄƒ pe graniÈ›e:** Generarea sinteticÄƒ a 1.000 de exemple suplimentare fix Ã®n intervalul problematic (10mm - 20mm eroare) pentru a forÈ›a modelul sÄƒ Ã®nveÈ›e mai bine aceastÄƒ tranziÈ›ie finÄƒ.
3.  **AdÄƒugarea caracteristicii "Jerk" (Derivata acceleraÈ›iei):** Introducerea È™ocului mecanic ca input (Input #9). Chiar dacÄƒ poziÈ›ia pare ok, un "Jerk" mare indicÄƒ clar o problemÄƒ mecanicÄƒ (uzurÄƒ rulmenÈ›i), ajutÃ¢nd la discriminarea claselor Ã®n zonele de suprapunere.

## Structura Repository-ului la Finalul Etapei 5

**Clarificare organizare:** Vom folosi **README-uri separate** pentru fiecare etapÄƒ Ã®n folderul `docs/`:

```
proiect-rn-[prenume-nume]/
â”œâ”€â”€ README.md                           # Overview general proiect (actualizat)
â”œâ”€â”€ etapa3_analiza_date.md         # Din Etapa 3
â”œâ”€â”€ etapa4_arhitectura_sia.md      # Din Etapa 4
â”œâ”€â”€ etapa5_antrenare_model.md      # â† ACEST FIÈ˜IER (completat)
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ state_machine.png              # Din Etapa 4
â”‚   â”œâ”€â”€ loss_curve.png                 # NOU - Grafic antrenare
â”‚   â”œâ”€â”€ confusion_matrix.png           # (opÈ›ional - Nivel 3)
â”‚   â””â”€â”€ screenshots/
â”‚       â”œâ”€â”€ inference_real.png         # NOU - OBLIGATORIU
â”‚       â””â”€â”€ ui_demo.png                # Din Etapa 4
â”‚
â”œâ”€â”€ data/                               # Din Etapa 3-4 (NESCHIMBAT)
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ generated/                     # ContribuÈ›ia voastrÄƒ 40%
â”‚   â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ validation/
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_acquisition/              # Din Etapa 4
â”‚   â”œâ”€â”€ preprocessing/                 # Din Etapa 3
â”‚   â”‚   â””â”€â”€ combine_datasets.py        # NOU (dacÄƒ aÈ›i adÄƒugat date Ã®n Etapa 4)
â”‚   â”œâ”€â”€ neural_network/
â”‚   â”‚   â”œâ”€â”€ model.py                   # Din Etapa 4
â”‚   â”‚   â”œâ”€â”€ train.py                   # NOU - Script antrenare
â”‚   â”‚   â””â”€â”€ evaluate.py                # NOU - Script evaluare
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ main.py                    # ACTUALIZAT - Ã®ncarcÄƒ model antrenat
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ untrained_model.h5             # Din Etapa 4
â”‚   â”œâ”€â”€ trained_model.h5               # NOU - OBLIGATORIU
â”‚   â””â”€â”€ final_model.onnx               # (opÈ›ional - Nivel 3 bonus)
â”‚
â”œâ”€â”€ results/                            # NOU - Folder rezultate antrenare
â”‚   â”œâ”€â”€ training_history.csv           # OBLIGATORIU - toate epoch-urile
â”‚   â”œâ”€â”€ test_metrics.json              # Metrici finale pe test set
â”‚   â””â”€â”€ hyperparameters.yaml           # Hiperparametri folosiÈ›i
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ preprocessing_params.pkl       # Din Etapa 3 (NESCHIMBAT)
â”‚
â”œâ”€â”€ requirements.txt                    # Actualizat
â””â”€â”€ .gitignore
```

**DiferenÈ›e faÈ›Äƒ de Etapa 4:**
- AdÄƒugat `docs/etapa5_antrenare_model.md` (acest fiÈ™ier)
- AdÄƒugat `docs/loss_curve.png` (Nivel 2)
- AdÄƒugat `models/trained_model.h5` - OBLIGATORIU
- AdÄƒugat `results/` cu history È™i metrici
- AdÄƒugat `src/neural_network/train.py` È™i `evaluate.py`
- Actualizat `src/app/main.py` sÄƒ Ã®ncarce model antrenat

---

## InstrucÈ›iuni de Rulare (Actualizate faÈ›Äƒ de Etapa 4)

### 1. Setup mediu (dacÄƒ nu aÈ›i fÄƒcut deja)

```bash
pip install -r requirements.txt
```

### 2. PregÄƒtire date (DACÄ‚ aÈ›i adÄƒugat date noi Ã®n Etapa 4)

```bash
# Combinare + reprocesare dataset complet
python src/preprocessing/combine_datasets.py
python src/preprocessing/data_cleaner.py
python src/preprocessing/feature_engineering.py
python src/preprocessing/data_splitter.py --stratify --random_state 42
```

### 3. Antrenare model

```bash
python src/neural_network/train.py --epochs 50 --batch_size 32 --early_stopping

# Output aÈ™teptat:
# Epoch 1/50 - loss: 0.8234 - accuracy: 0.6521 - val_loss: 0.7891 - val_accuracy: 0.6823
# ...
# Epoch 23/50 - loss: 0.3456 - accuracy: 0.8234 - val_loss: 0.4123 - val_accuracy: 0.7956
# Early stopping triggered at epoch 23
# âœ“ Model saved to models/trained_model.h5
```

### 4. Evaluare pe test set

```bash
python src/neural_network/evaluate.py --model models/trained_model.h5

# Output aÈ™teptat:
# Test Accuracy: 0.7823
# Test F1-score (macro): 0.7456
# âœ“ Metrics saved to results/test_metrics.json
# âœ“ Confusion matrix saved to docs/confusion_matrix.png
```

### 5. Lansare UI cu model antrenat

```bash
streamlit run src/app/main.py

# SAU pentru LabVIEW:
# DeschideÈ›i WebVI È™i rulaÈ›i main.vi
```

**Testare Ã®n UI:**
1. IntroduceÈ›i date de test (manual sau upload fiÈ™ier)
2. VerificaÈ›i cÄƒ predicÈ›ia este DIFERITÄ‚ de Etapa 4 (cÃ¢nd era random)
3. VerificaÈ›i cÄƒ confidence scores au sens (ex: 85% pentru clasa corectÄƒ)
4. FaceÈ›i screenshot â†’ salvaÈ›i Ã®n `docs/screenshots/inference_real.png`

---

## Checklist Final â€“ BifaÈ›i Totul Ãnainte de Predare

### 1. Prerequisite Etapa 4 (Verificare)
- [x] State Machine existÄƒ È™i e documentat Ã®n `docs/state_machine.*`
- [x] ContribuÈ›ie â‰¥40% date originale verificabilÄƒ Ã®n `data/generated/` (Scriptul genereazÄƒ 100% date)
- [x] Cele 3 module din Etapa 4 funcÈ›ionale (`antrenare`, `testare`, `bonus`)

### 2. Preprocesare È™i Date
- [x] Dataset combinat È™i preprocesat (`baza_de_date_robot.csv`)
- [x] Split train/val/test: 70/15/15% (Implementat Ã®n `antrenare_nivel2.py`)
- [x] Scaler salvat È™i folosit consistent (`models/scaler_spdt.gz`)

### 3. Antrenare Model - Nivel 1 (OBLIGATORIU)
- [x] Model antrenat de la ZERO (ArhitecturÄƒ MLP definitÄƒ Ã®n cod)
- [x] Minimum 10 epoci rulate (Setat 50 cu Early Stopping)
- [x] Tabel hiperparametri + justificÄƒri completat Ã®n README
- [x] Metrici calculate pe test set: **Accuracy â‰¥65%**, **F1 â‰¥0.60** (ObÈ›inut >99%)
- [x] Model salvat Ã®n `models/trained_model.h5`
- [x] `results/training_history.csv` generat (AsigurÄƒ-te cÄƒ ai adÄƒugat liniile de export CSV Ã®n cod)

### 4. Integrare UI È™i DemonstraÈ›ie - Nivel 1 (OBLIGATORIU)
- [x] Model ANTRENAT Ã®ncÄƒrcat Ã®n UI (`testare_etapa5.py`)
- [x] UI face inferenÈ›Äƒ REALÄ‚ cu predicÈ›ii corecte (Vizualizare Matplotlib)
- [x] **ACÈšIUNE:** Screenshot inferenÈ›Äƒ realÄƒ salvat Ã®n `docs/screenshots/inference_real.png`
- [x] Verificat: predicÈ›iile sunt deterministe (bazate pe input), nu random

### 5. DocumentaÈ›ie Nivel 2 (ExcelenÈ›Äƒ)
- [x] Early stopping implementat È™i documentat Ã®n cod
- [x] Learning rate scheduler folosit (`ReduceLROnPlateau`)
- [x] AugmentÄƒri relevante domeniu aplicate (Jitter / Zgomot Gaussian)
- [x] Grafic loss/val_loss salvat automat Ã®n `docs/loss_curve.png`
- [x] AnalizÄƒ erori Ã®n context industrial completatÄƒ Ã®n README
- [x] Metrici Nivel 2 atinse: **Accuracy â‰¥75%**, **F1 â‰¥0.70**

### 6. DocumentaÈ›ie Nivel 3 (Bonus)
- [x] ComparaÈ›ie 2+ arhitecturi (MLP vs Random Forest) inclusÄƒ Ã®n README
- [x] Confusion matrix + analizÄƒ exemple greÈ™ite inclusÄƒ Ã®n README
- [ ] Export ONNX (OpÈ›ional/Lite: s-a realizat doar analiza comparativÄƒ È™i de erori)

### 7. VerificÄƒri Tehnice
- [ ] **ACÈšIUNE:** `requirements.txt` generat (`pip freeze > requirements.txt`)
- [x] Toate path-urile sunt RELATIVE (ex: `models/`, nu `C:/Users/...`)
- [x] Codul este comentat È™i explicat
- [ ] **ACÈšIUNE:** `git log` aratÄƒ commit-uri incrementale

### 8. Verificare State Machine
- [x] Fluxul de inferenÈ›Äƒ din `testare_etapa5.py` respectÄƒ stÄƒrile din diagramÄƒ
- [x] Scaler-ul È™i Modelul sunt aceleaÈ™i Ã®n Antrenare È™i Testare

### 9. Pre-Predare (PaÈ™i Finali)
- [ ] `README.md` completat cu toate secÈ›iunile (Tabele, Analize, Checklist)
- [ ] StructurÄƒ folder curatÄƒ (`models/`, `docs/`, `results/`)
- [ ] **ACÈšIUNE:** Commit final: `"Etapa 5 completÄƒ â€“ Accuracy=99%"`
- [ ] **ACÈšIUNE:** Push pe GitHub/GitLab

---

## Livrabile Obligatorii (Nivel 1)

AsiguraÈ›i-vÄƒ cÄƒ urmÄƒtoarele fiÈ™iere existÄƒ È™i sunt completate:

1. **`docs/etapa5_antrenare_model.md`** (acest fiÈ™ier) cu:
   - Tabel hiperparametri + justificÄƒri (complet)
   - Metrici test set raportate (accuracy, F1)
   - (Nivel 2) AnalizÄƒ erori context industrial (4 paragrafe)

2. **`models/trained_model.h5`** (sau `.pt`, `.lvmodel`) - model antrenat funcÈ›ional

3. **`results/training_history.csv`** - toate epoch-urile salvate

4. **`results/test_metrics.json`** - metrici finale:

Exemplu:
```json
{
  "test_accuracy": 0.7823,
  "test_f1_macro": 0.7456,
  "test_precision_macro": 0.7612,
  "test_recall_macro": 0.7321
}
```

5. **`docs/screenshots/inference_real.png`** - demonstraÈ›ie UI cu model antrenat

6. **(Nivel 2)** `docs/loss_curve.png` - grafic loss vs val_loss

7. **(Nivel 3)** `docs/confusion_matrix.png` + analizÄƒ Ã®n README

---

## Predare È™i Contact

**Predarea se face prin:**
1. Commit pe GitHub: `"Etapa 5 completÄƒ â€“ Accuracy=X.XX, F1=X.XX"`
2. Tag: `git tag -a v0.5-model-trained -m "Etapa 5 - Model antrenat"`
3. Push: `git push origin main --tags`

---


**Mult succes! AceastÄƒ etapÄƒ demonstreazÄƒ cÄƒ Sistemul vostru cu InteligenÈ›Äƒ ArtificialÄƒ (SIA) funcÈ›ioneazÄƒ Ã®n condiÈ›ii reale!**


